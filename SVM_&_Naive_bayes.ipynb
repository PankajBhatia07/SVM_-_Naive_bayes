{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIFCCrpnp8GC"
      },
      "source": [
        "# ***Theory Question***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6xS2GijbHmf"
      },
      "source": [
        "## **Q1.What is a Support Vector Machine (SVM)?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWsxi4i8bOVG"
      },
      "source": [
        "A Support Vector Machine (SVM) is a supervised machine learning algorithm used for classification and regression tasks. It works by finding the optimal hyperplane that best separates data points of different classes in a high-dimensional space.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNIZx-TebHpo"
      },
      "source": [
        "## **Q2. What is the difference between Hard Margin and Soft Margin SVM?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJDL_OvpbY5Y"
      },
      "source": [
        "The difference between Hard Margin and Soft Margin SVM lies in how strictly the model separates the data:\n",
        "\n",
        "- **Hard Margin SVM:**\n",
        "\n",
        " - Assumes data is perfectly linearly separable.\n",
        "\n",
        " - No misclassification is allowed.\n",
        "\n",
        " - Finds the maximum-margin hyperplane with zero tolerance for errors.\n",
        "\n",
        " - Not suitable for noisy or overlapping data.\n",
        "\n",
        "- **Soft Margin SVM:**\n",
        "\n",
        " - Allows some misclassifications or violations.\n",
        "\n",
        " * Introduces a penalty parameter (C) to balance margin size and classification error.\n",
        "\n",
        " - More flexible and works better with real-world, noisy data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk0cd17Qb6X7"
      },
      "source": [
        "## **Q3.What is the mathematical intuition behind SVM?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_cOblCqffh5"
      },
      "source": [
        "**Mathematical Intuition Behind SVM**\n",
        "\n",
        "The mathematical intuition behind SVM is to find the hyperplane that **maximizes the margin** between two classes. Here's a simplified breakdown:\n",
        "\n",
        "\n",
        "**1. Hyperplane**\n",
        "\n",
        "A hyperplane in an $n$-dimensional space separates the data into classes. It‚Äôs defined as:\n",
        "\n",
        "$$\\mathbf{w} \\cdot \\mathbf{x} + b = 0\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $\\mathbf{w}$ is the **weight vector** (normal to the hyperplane)  \n",
        "- $\\mathbf{x}$ is the **input feature vector**  \n",
        "- $b$ is the **bias**\n",
        "\n",
        "\n",
        "\n",
        "**2. Margin**\n",
        "\n",
        "Margin is the distance between the hyperplane and the nearest data points from each class (called support vectors). SVM aims to maximize this margin:\n",
        "\n",
        "$$\\text{Margin} = \\frac{2}{\\|\\mathbf{w}\\|}\n",
        "$$\n",
        "\n",
        "So, to maximize the margin, we minimize $\\mathbf{||w||^2}$ , subject to the constraint:\n",
        "\n",
        "$$y_i(\\mathbf{w} \\cdot \\mathbf{x}_i + b) \\geq 1$$\n",
        "\n",
        "for all training examples $(\\mathbf{x}_i, y_i)$, where $y_i \\in \\{-1, +1\\}$.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**3. Soft Margin (with Slack Variables)**\n",
        "\n",
        "For non-linearly separable data, we allow some violations using slack variables $\\xi_i$:\n",
        "\n",
        "$$y_i(\\mathbf{w} \\cdot \\mathbf{x}_i + b) \\geq 1 - \\xi_i \\quad \\text{and} \\quad \\xi_i \\geq 0 $$\n",
        "\n",
        "The new objective becomes:\n",
        "\n",
        "$$\n",
        "\\min \\left( \\frac{1}{2} \\|\\mathbf{w}\\|^2 + C \\sum_{i=1}^{n} \\xi_i \\right)$$\n",
        "\n",
        "Where **C** is a regularization parameter that balances margin size and classification error.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN6ZQr979sgq"
      },
      "source": [
        "## **Q4. What is the role of Lagrange Multipliers in SVM?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJ4jxYLP98XX"
      },
      "source": [
        "**Objective of SVM:**\n",
        "\n",
        "SVM aims to find the optimal hyperplane that maximizes the margin (distance between the hyperplane and the nearest data points from both classes) for a given labeled training dataset.\n",
        "\n",
        "**The Optimization Problem (Primal Form)**\n",
        "\n",
        "For a linearly separable dataset, the primal optimization problem is:\n",
        "\n",
        "$$\\min_{w, b} \\ \\frac{1}{2} \\|w\\|^2$$\n",
        "\n",
        "Subject to:\n",
        "\n",
        "$$y_i (w^T x_i + b) \\geq 1 \\quad \\text{for all } i$$\n",
        "\n",
        "Where:\n",
        "- w: weight vector  \n",
        "- *b* : bias term  \n",
        "-  $x_i,y_i$: input data and labels  \n",
        "\n",
        "- This is a constrained quadratic optimization problem.\n",
        "\n",
        "\n",
        "**Introducing Lagrange Multipliers**\n",
        "\n",
        "To solve this constrained optimization problem, we introduce Lagrange multipliers $ \\alpha_i \\geq 0 $ for each constraint.\n",
        "\n",
        "We form the Lagrangian:\n",
        "\n",
        "$$ L(w, b, \\alpha) = \\frac{1}{2} \\|w\\|^2 - \\sum_{i=1}^{n} \\alpha_i \\left[ y_i (w^T x_i + b) - 1 \\right]$$\n",
        "\n",
        "Here:\n",
        "- $\\alpha_i$: Lagrange multipliers\n",
        "\n",
        "- The solution must satisfy the Karush-Kuhn-Tucker (KKT) conditions, which are optimality conditions for constrained optimization.\n",
        "\n",
        "-\n",
        "\n",
        "**Dual Problem**\n",
        "\n",
        "Rather than solving the primal directly, we convert it to the dual problem by maximizing the Lagrangian with respect to $\\alpha$, while minimizing it with respect to $\\ w $ and $ b $:\n",
        "\n",
        "$$\\max_{\\alpha} \\sum_{i=1}^n \\alpha_i - \\frac{1}{2} \\sum_{i=1}^{n} \\sum_{j=1}^{n} \\alpha_i \\alpha_j y_i y_j (x_i^T x_j)$$\n",
        "\n",
        "Subject to:\n",
        "\n",
        "\n",
        "$$\\sum_{i=1}^n \\alpha_i y_i = 0, \\quad \\alpha_i \\geq 0$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHgxRcejBQxc"
      },
      "source": [
        "## **Q5.What are Support Vectors in SVM?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9djrzcwB5iB"
      },
      "source": [
        "Support Vectors are the critical data points in a Support Vector Machine (SVM) that lie closest to the decision boundary (hyperplane). They are the most influential points that determine the position and orientation of the optimal hyperplane.\n",
        "\n",
        "**Graphical Intuition:**\n",
        "\n",
        "- In a 2D example with two linearly separable classes:\n",
        "\n",
        "- The SVM tries to find the maximum-margin hyperplane (a line, in 2D) that best separates the classes.\n",
        "\n",
        "- The margin is defined by the distance to the nearest data points on either side ‚Äî these are your support vectors.\n",
        "\n",
        "- Only these support vectors influence the hyperplane. Moving any non-support vector doesn't affect the hyperplane.\n",
        "\n",
        "**Mathematically:**\n",
        "\n",
        "In the dual formulation of SVM:\n",
        "\n",
        "$$f(x) = \\sum_{i=1}^{n} \\alpha_i y_i K(x_i, x) + b$$\n",
        "\n",
        "- Only points where $\\alpha_i > 0 $ are support vectors.\n",
        "- All others have  $\\alpha_i = 0 $, meaning they don‚Äôt impact the final decision boundary.\n",
        "\n",
        "\n",
        "**Why are Support Vectors Important?**\n",
        "\n",
        "**1.Efficiency:** Only a subset of the training data (support vectors) is used to make predictions.\n",
        "\n",
        "**2. Robustness:** They represent the most difficult-to-classify examples, making the model more resilient.\n",
        "\n",
        "**3.Sparsity:** Because only a few $ùõº_i$ are non-zero, SVM solutions are typically sparse (computationally efficient).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofxyIwKdEFq1"
      },
      "source": [
        "## **Q6.What is a Support Vector Classifier (SVC)?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcPS5SY3Hf8C"
      },
      "source": [
        "A Support Vector Classifier (SVC) is a type of Support Vector Machine (SVM) model specifically used for classification tasks. It constructs an optimal decision boundary (called a hyperplane) to separate classes of data with the maximum margin.\n",
        "\n",
        "**Core Idea:**\n",
        "\n",
        "**Hard Margin SVC (linearly separable data):**\n",
        "\n",
        "\n",
        "$$\\min_{w, b} \\ \\frac{1}{2} \\|w\\|^2$$\n",
        "\n",
        "Subject to:\n",
        "\n",
        "\n",
        "$$y_i (w^T x_i + b) \\geq 1 \\quad \\forall i$$\n",
        "\n",
        "**Soft Margin SVC (Non-Separable Data)**\n",
        "\n",
        "$$\\min_{w, b, \\xi} \\ \\frac{1}{2} \\|w\\|^2 + C \\sum_{i=1}^n \\xi_i$$\n",
        "\n",
        "Subject to:\n",
        "\n",
        "\n",
        "$$y_i (w^T x_i + b) \\geq 1 - \\xi_i, \\quad \\xi_i \\geq 0$$\n",
        "\n",
        "Where:\n",
        "\n",
        "- $\\xi_i $: Slack variables that allow margin violations  \n",
        "- $ C $: Penalty parameter that balances margin size and classification error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fmnmczg0I4jq"
      },
      "source": [
        "## **Q7.What is a Support Vector Regressor (SVR)?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcRdJ2g-JMO6"
      },
      "source": [
        "Support Vector Regression (SVR) is the regression counterpart of Support Vector Machines (SVM). Instead of finding a hyperplane that separates classes, SVR tries to fit the best line (or curve) that predicts continuous values, with a focus on a margin of tolerance.\n",
        "\n",
        "\n",
        "**Objective:**\n",
        "\n",
        "SVR attempts to find a function $f(x) $ that has at most $\\varepsilon $ deviation from the actual targets $y_i$, for all training data, and is as flat as possible.\n",
        "\n",
        "**Optimization Problem (Œµ-insensitive loss):**\n",
        "\n",
        "$$\\min_{w, b, \\xi_i, \\xi_i^*} \\ \\frac{1}{2} \\|w\\|^2 + C \\sum_{i=1}^n (\\xi_i + \\xi_i^*)$$\n",
        "\n",
        "Subject to:\n",
        "\n",
        "$$y_i - (w^T x_i + b) \\leq \\varepsilon + \\xi_i\n",
        "$$\n",
        "$$(w^T x_i + b) - y_i \\leq \\varepsilon + \\xi_i^*$$\n",
        "$$\\xi_i, \\xi_i^* \\geq 0$$\n",
        "\n",
        "\n",
        "**Key Terms:**\n",
        "\n",
        "- $\\varepsilon $: Defines the margin of tolerance (tube) around the predicted values.\n",
        "- $\\xi_i, \\xi_i^* $: Slack variables to allow deviations outside the margin.\n",
        "- $C$: Regularization parameter controlling the trade-off between model complexity and tolerance to deviations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOnkLs1SKgI_"
      },
      "source": [
        "## **Q8.What is the Kernel Trick in SVM?**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1z80PS5MEOL"
      },
      "source": [
        "In Support Vector Machines (SVM), the **Kernel Trick** allows us to perform non-linear classification by implicitly mapping input features into a higher-dimensional space, without explicitly computing the transformation.\n",
        "\n",
        "\n",
        "**Kernel Trick in Action:**\n",
        "\n",
        "- If $\\phi(x) $ is a transformation function that maps input data into a higher-dimensional space, then:\n",
        "\n",
        "\n",
        "$$K(x_i, x_j) = \\langle \\phi(x_i), \\phi(x_j) \\rangle$$\n",
        "\n",
        "- This avoids the need to compute $\\phi(x)$ explicitly, saving computational cost.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SpTqoZkNBv9"
      },
      "source": [
        "**Common Kernel Functions:**\n",
        "\n",
        "| Kernel Type    | Formula                            |   |         |   |    |\n",
        "| -------------- | ---------------------------------- | - | ------- | - | -- |\n",
        "| Linear         | K(x·µ¢, x‚±º) = x·µ¢·µÄ ¬∑ x‚±º               |   |         |   |    |\n",
        "| Polynomial     | K(x·µ¢, x‚±º) = (Œ≥ ¬∑ x·µ¢·µÄ ¬∑ x‚±º + r)·µà    |   |         |   |    |\n",
        "| RBF (Gaussian) | K(x·µ¢, x‚±º) = exp(‚ÄìŒ≥ ¬∑ x·µ¢ ‚Äì x‚±º¬≤) |\n",
        "|\n",
        "Sigmoid        | K(x·µ¢, x‚±º) = tanh(Œ≥ ¬∑ x·µ¢·µÄ ¬∑ x‚±º + r) |   |         |   |    |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1U3UGu8NMAS"
      },
      "source": [
        "## **Q9.Compare Linear Kernel, Polynomial Kernel, and RBF Kernel?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wpq-wvwOXTl"
      },
      "source": [
        "| Aspect                        | Linear Kernel                                                          | Polynomial Kernel                                                    | RBF (Radial Basis Function) Kernel                                 |\n",
        "| ----------------------------- | ---------------------------------------------------------------------- | -------------------------------------------------------------------- | ------------------------------------------------------------------ |\n",
        "| **Formula**                   | $K(x_i, x_j) = x_i^T x_j$                                              | $K(x_i, x_j) = (\\gamma x_i^T x_j + r)^d$                             | $K(x_i, x_j) = \\exp(-\\gamma \\|x_i - x_j\\|^2)$                      |\n",
        "| **Type of decision boundary** | Linear hyperplane                                                      | Non-linear, polynomial-shaped                                        | Highly non-linear, flexible                                        |\n",
        "| **Feature mapping**           | No explicit mapping, works in original feature space                   | Maps data into polynomial feature space of degree $d$                | Maps data into infinite-dimensional space implicitly               |\n",
        "| **Hyperparameters**           | None or just regularization $C$                                        | Degree $d$, coefficient $r$, $\\gamma$, and $C$                       | $\\gamma$ and $C$                                                   |\n",
        "| **When to use**               | Data is linearly separable or high-dimensional sparse data (like text) | When relationship is polynomial or curved but with global structure  | When complex boundaries are needed, data is not linearly separable |\n",
        "| **Advantages**                | Fast, simple, less prone to overfitting                                | Can model curved boundaries, more flexible than linear               | Very flexible, handles complex patterns well                       |\n",
        "| **Disadvantages**             | Cannot capture non-linear patterns                                     | Computationally expensive with large degree $d$, risk of overfitting | Computationally expensive, sensitive to parameter tuning           |\n",
        "| **Computational cost**        | Low                                                                    | Moderate to high, increases with degree $d$                          | High, depends on number of support vectors                         |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNgjknwGOgaI"
      },
      "source": [
        "## **Q10.What is the effect of the C parameter in SVM?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9HYsOZvO08a"
      },
      "source": [
        "**Effect of C in SVM:**\n",
        "\n",
        "**High C value (Large penalty):**\n",
        "\n",
        "* The SVM tries to classify all training points correctly by penalizing misclassification heavily.\n",
        "\n",
        "* This leads to a smaller margin because the model focuses on minimizing classification errors on the training set.\n",
        "\n",
        "* Risk: Overfitting ‚Äî the model fits training data very closely and may not generalize well.\n",
        "\n",
        "**Low C value (Small penalty):**\n",
        "\n",
        "* The SVM allows some misclassifications (slack variables) to achieve a larger margin.\n",
        "\n",
        "* The model is more tolerant to errors on training data to gain better generalization on unseen data.\n",
        "\n",
        "* Risk: Underfitting if C is too small, as the margin might be too wide and the model too simple.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PluznNZPHY2"
      },
      "source": [
        "**Intuition:**\n",
        "\n",
        "- C controls the flexibility of the decision boundary:\n",
        "\n",
        "| C Value | Effect on Model                                                  |\n",
        "| ------- | ---------------------------------------------------------------- |\n",
        "| Large   | Strict, tries to fit all data points correctly, complex boundary |\n",
        "| Small   | More flexible, allows some errors, smoother and simpler boundary |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRCmfTUKPRCs"
      },
      "source": [
        "## **Q11.What is the role of the Gamma parameter in RBF Kernel SVM?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXUIaquePYMe"
      },
      "source": [
        "The Gamma (Œ≥) parameter in an RBF (Radial Basis Function) kernel SVM controls the influence of a single training example on the decision boundary.\n",
        "\n",
        "- **Defines the reach of a single training point's influence:**\n",
        "\n",
        "- **Small Œ≥ (low value):**\n",
        "\n",
        "Each training point's influence is far-reaching ‚Äî points far away still affect the decision boundary.\n",
        "This creates a smooth, simple decision boundary that may underfit if Œ≥ is too low.\n",
        "\n",
        "- **Large Œ≥ (high value):**\n",
        "\n",
        "Each point's influence is limited to a small area around itself.\n",
        "This allows the decision boundary to be very complex and wiggly, fitting closely around training points, which can cause overfitting.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wONupZF6QluE"
      },
      "source": [
        "**Intuition:**\n",
        "\n",
        "| Gamma (Œ≥) value | Effect on Decision Boundary                        |\n",
        "| --------------- | -------------------------------------------------- |\n",
        "| Small           | Smooth, less complex boundary; more generalization |\n",
        "| Large           | Complex, tightly fit boundary; risk of overfitting |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJijhHBFQqeB"
      },
      "source": [
        "## **Q12. What is the Na√Øve Bayes classifier, and why is it called \"Na√Øve\"?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8VczUQIQzUa"
      },
      "source": [
        "Na√Øve Bayes classifier is a simple probabilistic machine learning model used for classification tasks. It is based on applying Bayes‚Äô theorem with a strong assumption that all features are independent of each other given the class label.\n",
        "\n",
        "- It calculates the probability of a data point belonging to each class using Bayes' theorem:\n",
        "\n",
        "\n",
        "$$P(C \\mid X) = \\frac{P(X \\mid C) \\times P(C)}{P(X)}$$\n",
        "\n",
        "where:\n",
        "\n",
        "- $P(C \\mid X) $ is the posterior probability of class $ C $ given features $ X $,\n",
        "- $ P(X \\mid C) $ is the likelihood of features given class,\n",
        "- $ P(C) $ is the prior probability of the class,\n",
        "- $ P(X) $ is the probability of the features.\n",
        "\n",
        "- The classifier predicts the class with the highest posterior probability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4Bi_P8bRhxS"
      },
      "source": [
        "**Why is it called \"Na√Øve\"**\n",
        "- The model assumes that all features are conditionally independent given the class ‚Äî which is rarely true in real-world data.\n",
        "\n",
        "- This simplifying assumption is called ‚Äúna√Øve‚Äù because it ignores possible correlations among features.\n",
        "\n",
        "- Despite this ‚Äúna√Øve‚Äù assumption, it often performs surprisingly well in many applications like spam filtering, text classification, and medical diagnosis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jL3Mn9cUBFb"
      },
      "source": [
        "## **Q13.What is Bayes‚Äô Theorem?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ixNeiJLUQKD"
      },
      "source": [
        "Bayes‚Äô Theorem is a fundamental rule in probability theory that describes how to update the probability of a hypothesis based on new evidence.\n",
        "\n",
        "The Formula:\n",
        "\n",
        "\n",
        "$$P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}$$\n",
        "\n",
        "where:\n",
        "\n",
        "- $ùëÉ\n",
        "(\n",
        "ùê¥\n",
        "‚à£\n",
        "ùêµ\n",
        ")$: **Posterior probability** ‚Äî the probability of event\n",
        "$ùê¥$ occurring given that\n",
        "$ùêµ$ has occurred.\n",
        "\n",
        "- $ùëÉ\n",
        "(\n",
        "ùêµ\n",
        "‚à£\n",
        "ùê¥\n",
        ")$: **Likelihood** ‚Äî the probability of observing event\n",
        "$ùêµ$ given that\n",
        "$ùê¥$ is true.\n",
        "\n",
        "\n",
        "- $ùëÉ\n",
        "(\n",
        "ùê¥\n",
        ")$: **Prior probability** ‚Äî the initial probability of event\n",
        "$ùê¥$ before observing\n",
        "$ùêµ$.\n",
        "\n",
        "\n",
        "- $ùëÉ\n",
        "(\n",
        "ùêµ\n",
        ")$: **Marginal probability** ‚Äî the total probability of event $ùêµ$ occurring.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "If $ùê¥$ = \"It will rain today\" and $ùêµ$ = \"The sky is cloudy\", Bayes‚Äô theorem helps you calculate the probability it will rain given the sky is cloudy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5FK8W7vWDOz"
      },
      "source": [
        "## **Q14.Explain the differences between Gaussian Na√Øve Bayes, Multinomial Na√Øve Bayes, and Bernoulli Na√Øve Bayes.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFYDsg10XAby"
      },
      "source": [
        "| Na√Øve Bayes Type            | Use Case                             | Feature Type          | Assumption on Features                |\n",
        "| --------------------------- | ------------------------------------ | --------------------- | ------------------------------------- |\n",
        "| **Gaussian Na√Øve Bayes**    | Continuous data (e.g., IRIS dataset) | Real-valued features  | Features follow a normal distribution |\n",
        "| **Multinomial Na√Øve Bayes** | Discrete counts (e.g., word counts)  | Count-based features  | Features represent frequency/count    |\n",
        "| **Bernoulli Na√Øve Bayes**   | Binary/Boolean features (e.g., spam) | Binary features (0/1) | Features are present/absent           |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKxpiLB5XXSS"
      },
      "source": [
        "**Gaussian Na√Øve Bayes**\n",
        "\n",
        "* **Used for**: Real-valued features like heights, weights, or pixel intensities.\n",
        "\n",
        "* **Formula:**\n",
        "\n",
        "\n",
        "$$P(x_i \\mid C_k) = \\frac{1}{\\sqrt{2\\pi\\sigma_k^2}} \\exp\\left( -\\frac{(x_i - \\mu_k)^2}{2\\sigma_k^2} \\right)$$\n",
        "\n",
        "**Multinomial Na√Øve Bayes**\n",
        "- **Used for:** Count data, especially in text classification (e.g., how often each word appears).\n",
        "\n",
        "- **Assumes:** Features represent discrete frequencies (non-negative integers).\n",
        "\n",
        "- **Best for:** Document classification, spam detection, etc.\n",
        "\n",
        "- **Note:** Doesn't work well with negative or continuous values.\n",
        "\n",
        "**Bernoulli Na√Øve Bayes**\n",
        "- **Used for:** Binary/Boolean data (e.g., presence or absence of a feature).\n",
        "\n",
        "- **Assumes:** Features are binary (e.g., word present: 1 or absent: 0).\n",
        "\n",
        "- **Best for:** Simple spam filters, sentiment analysis (binary features).\n",
        "\n",
        "- **Important:** Penalizes words that don‚Äôt appear in a document."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSiuhDJ5YqdG"
      },
      "source": [
        "## **Q15.When should you use Gaussian Na√Øve Bayes over other variants?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF6NcUxdY4Ub"
      },
      "source": [
        "Use Gaussian Na√Øve Bayes when:\n",
        "\n",
        "| Scenario                                             | Explanation                                                                             |\n",
        "| ---------------------------------------------------- | --------------------------------------------------------------------------------------- |\n",
        "| **Continuous features**                           | The input data consists of real-valued numbers (e.g., height, weight, sensor readings). |\n",
        "| **Features look normally distributed**            | Histograms or statistical tests show that features follow a bell-shaped curve.          |\n",
        "|  **Examples**                                      | Medical data (e.g., blood pressure), Iris dataset, or other scientific measurements.    |\n",
        "| **Need fast, scalable classification**            | Gaussian NB is computationally efficient, even with many features.                      |\n",
        "| **Independence assumption holds reasonably well** | Features are not heavily correlated or dependent on one another.                        |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhU7dipKZLVk"
      },
      "source": [
        "**Avoid Gaussian Na√Øve Bayes when:**\n",
        "\n",
        "* You‚Äôre dealing with text data (use Multinomial NB instead).\n",
        "\n",
        "* Features are binary (use Bernoulli NB).\n",
        "\n",
        "* Features have categorical values without ordering (use other models like Decision Trees or Categorical NB).\n",
        "\n",
        "**Example Use Case:**\n",
        "\n",
        "Predicting whether a patient has a disease based on continuous inputs like blood sugar, BMI, age, etc., where each feature is approximately normally distributed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCLdqfhAZW2O"
      },
      "source": [
        "## **Q16.What are the key assumptions made by Na√Øve Bayes?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9E3iuWxIZgSz"
      },
      "source": [
        "| Assumption                                   | Description                                                                                                                                                                                                                                                     |\n",
        "| -------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **1. Feature Independence**                  | All features are **conditionally independent** given the class label.That is, the presence or absence of a feature does not affect any other feature's presence, **given the class**.                                                                          |\n",
        "| **2. Equal Importance of Features**          | Each feature contributes **equally and independently** to the probability of a class ‚Äî no feature interactions are considered.                                                                                                                                  |\n",
        "| **3. Correct Model of Feature Distribution** | Depends on the variant:<br> - **Gaussian NB** assumes features are **normally distributed**.<br> - **Multinomial NB** assumes features are **counts** (e.g., word frequency).<br> - **Bernoulli NB** assumes **binary** features (e.g., word presence/absence). |\n",
        "| **4. Class Prior is Known or Estimable**     | The model assumes prior probabilities of each class (i.e., $P(C)$) are either known or can be estimated from data.   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ND8AdZ6ZjdZ"
      },
      "source": [
        "## **Q17.What are the advantages and disadvantages of Na√Øve Bayes?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzQAQvKraRFM"
      },
      "source": [
        "**Advantages of Na√Øve Bayes:**\n",
        "\n",
        "- **Simple and Fast:** It's easy to implement and works very efficiently on large datasets.\n",
        "\n",
        "- **Requires Less Training Data:** Performs well even with relatively small amounts of training data.\n",
        "\n",
        "- **Effective with High-Dimensional Data:** Great for problems like text classification where the number of features (words) is very large.\n",
        "\n",
        "- **Works Well with Categorical Inputs:** Especially useful when dealing with discrete features like word counts or presence/absence.\n",
        "\n",
        "- **Performs Well in Many Real-World Cases:** Despite its \"na√Øve\" assumptions, it often gives surprisingly good results.\n",
        "\n",
        "\n",
        "**Disadvantages of Na√Øve Bayes:**\n",
        "\n",
        "- **Strong Independence Assumption:** Assumes that features are conditionally independent given the class, which is rarely true in real data.\n",
        "\n",
        "- **Zero Probability Problem:** If a feature value wasn‚Äôt seen during training, it may assign zero probability to that class ‚Äî requiring smoothing techniques like Laplace smoothing.\n",
        "\n",
        "- **Limited Expressiveness:** Cannot capture complex relationships or interactions between features.\n",
        "\n",
        "- **Sensitive to Data Distribution:** Gaussian Na√Øve Bayes assumes normal distribution, which might not fit real-world continuous data well.\n",
        "\n",
        "- **Not Ideal for Correlated Features:** When features are highly correlated, performance can degrade.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pT5o74TicNWV"
      },
      "source": [
        "## **Q18.Why is Na√Øve Bayes a good choice for text classification?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRBZVCS2cT_R"
      },
      "source": [
        " **Why Na√Øve Bayes Works Well for Text:**\n",
        "\n",
        "- **High-Dimensional Feature Space:**Text data (like emails or reviews) gets converted into a huge number of features (e.g., each word). Na√Øve Bayes handles this high dimensionality efficiently, especially using bag-of-words or TF-IDF representations.\n",
        "\n",
        "- **Feature Independence Works Well Enough:**\n",
        "Although words in natural language are not truly independent, the conditional independence assumption still leads to good performance in practice.\n",
        "\n",
        "- **Fast Training and Prediction:**\n",
        "Na√Øve Bayes is computationally efficient ‚Äî ideal for training on large text datasets and making fast predictions.\n",
        "\n",
        "- **Works Well Even with Small Datasets:**\n",
        "Because it estimates probabilities rather than optimizing weights, it requires less data to generalize well.\n",
        "\n",
        "- **Robust to Irrelevant Features:**\n",
        "Many words in text data don‚Äôt influence classification. Na√Øve Bayes tolerates noise and irrelevant features quite well.\n",
        "\n",
        "- **Effective for Binary or Frequency-based Features:**\n",
        "The Multinomial and Bernoulli versions of Na√Øve Bayes are designed for word counts or word presence, which matches how we process text.\n",
        "\n",
        "- **Good Baseline Model:**\n",
        "Even if more complex models are used later, Na√Øve Bayes often serves as a strong baseline due to its simplicity and solid performance.\n",
        "\n",
        "**Common Use Cases:**\n",
        "- **Spam detection**\n",
        "- **Sentiment analysis**\n",
        "- **News categorization**\n",
        "- **Language detection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4a6pBUhequ8"
      },
      "source": [
        "## **Q19.Compare SVM and Na√Øve Bayes for classification tasks?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9o4ecjgfuck"
      },
      "source": [
        "**1. Underlying Principle**\n",
        "\n",
        "- **SVM:**\n",
        "A discriminative classifier. It finds the optimal decision boundary (hyperplane) that maximizes the margin between classes.\n",
        "\n",
        "- **Na√Øve Bayes:**\n",
        "A generative classifier. It models the joint probability of features and classes using Bayes‚Äô Theorem, assuming feature independence.\n",
        "\n",
        "**2.Performance**\n",
        "\n",
        "- **SVM:**\n",
        "Generally more accurate on complex datasets with non-linear decision boundaries or correlated features.\n",
        "\n",
        "- **Na√Øve Bayes:**\n",
        "Faster and still performs well, especially on text classification, but may struggle when features are not independent.\n",
        "\n",
        "**3. Assumptions**\n",
        "- **SVM:**\n",
        "Makes no strong assumptions about the data distribution. Can handle correlated features.\n",
        "\n",
        "- **Na√Øve Bayes:**\n",
        "Assumes conditional independence of features ‚Äî often not true in practice but can still work well.\n",
        "\n",
        "**4. Speed and Efficiency**\n",
        "\n",
        "- **SVM:**\n",
        "Slower to train, especially with large datasets or high-dimensional features.\n",
        "\n",
        "- **Na√Øve Bayes:**\n",
        "Very fast to train and predict, even on large datasets.\n",
        "\n",
        "**5. Data Requirements**\n",
        "\n",
        "- **SVM:**\n",
        "Needs carefully scaled features and may require more data for tuning.\n",
        "\n",
        "- **Na√Øve Bayes:**\n",
        "Works well with small datasets, especially if the independence assumption holds reasonably well.\n",
        "\n",
        "**6. Handling of Noisy Data**\n",
        "\n",
        "- **SVM:**\n",
        "Sensitive to outliers, but soft margin SVMs help mitigate this.\n",
        "\n",
        "- **Na√Øve Bayes:**\n",
        "Robust to noise, especially in high-dimensional spaces like text data.\n",
        "\n",
        "**7. Interpretability**\n",
        "\n",
        "- **SVM:**\n",
        "Decision function is harder to interpret.\n",
        "\n",
        "- **Na√Øve Bayes:**\n",
        "Easier to understand, since it's based on probabilities and conditional independence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0pzSQMWkbVH"
      },
      "source": [
        "## **Q20.How does Laplace Smoothing help in Na√Øve Bayes?**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoPlIn75k4_Z"
      },
      "source": [
        "Laplace Smoothing (also called Additive Smoothing) is a technique used in Na√Øve Bayes to handle the problem of zero probability for unseen features during classification.\n",
        "\n",
        "The Problem:\n",
        "\n",
        "- In Na√Øve Bayes, probabilities like  $P(x_i \\mid C_k)$ are estimated from the training data.\n",
        "- If a feature (like a word in text classification) **never appears** in class $C_k $, then:  \n",
        "$$P(x_i \\mid C_k) = 0$$\n",
        "\n",
        "- This becomes a problem because Na√Øve Bayes **multiplies all feature probabilities**.  \n",
        "A single zero value will make the entire product zero, resulting in:  \n",
        "\n",
        "$$P(C_k \\mid x) = 0$$  \n",
        "‚Äîeven if other features **strongly suggest** that \\( C_k \\) is the correct class.\n",
        "\n",
        "\n",
        "**The Solution: Laplace Smoothing**\n",
        "\n",
        "We add 1 (or a small constant) to the count of each feature in every class. This ensures no probability is zero.\n",
        "\n",
        "**For categorical features:**\n",
        "\n",
        "\n",
        "$$P(x_i \\mid C_k) = \\frac{\\text{count}(x_i \\text{ in } C_k) + 1}{\\text{total count of all features in } C_k + V}$$\n",
        "\n",
        "where:\n",
        "- ùëâ is the number of possible feature values (e.g., vocabulary size in text classification).\n",
        "\n",
        "- The \"+1\" ensures even unseen features have a small, non-zero probability.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAYPY-jeqEss"
      },
      "source": [
        "# ***Practical Question***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOlEYITZqKfF"
      },
      "source": [
        "## **Q21.Write a Python program to train an SVM Classifier on the Iris dataset and evaluate accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hq0ZEp7LzTQ_"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "#split into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#feature scaling (important for SVM)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#create and train the SVM classifier\n",
        "svm_clf = SVC(kernel='linear')  # You can try 'rbf', 'poly', etc.\n",
        "svm_clf.fit(X_train, y_train)\n",
        "\n",
        "#make predictions\n",
        "y_pred = svm_clf.predict(X_test)\n",
        "\n",
        "#evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of the SVM classifier on the Iris dataset: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emlA_M-yhZZV"
      },
      "source": [
        "## **Q22.Write a Python program to train two SVM classifiers with Linear and RBF kernels on the Wine dataset, then compare their accuracies:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ER3qRsDLhnZf"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#load the wine dataset\n",
        "wine = datasets.load_wine()\n",
        "X = wine.data\n",
        "y =wine.target\n",
        "\n",
        "#split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "#feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#train SVM with linear kernel\n",
        "svm_linear = SVC (kernel='linear')\n",
        "svm_linear.fit(X_train, y_train)\n",
        "y_pred = svm_linear.predict(X_test)\n",
        "accuracy_linear = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "#train SVM with RBF kernel\n",
        "svm_rbf = SVC(kernel='rbf')\n",
        "svm_rbf.fit(X_train, y_train)\n",
        "y_pred = svm_rbf.predict(X_test)\n",
        "accuracy_rbf = accuracy_score(y_test, y_pred)\n",
        "\n",
        "#display accuraties\n",
        "print(f\"Accuracy Linear Kernel: {accuracy_linear * 100:.2f}%\")\n",
        "print(f\"Accuracy RBF Kernel: {accuracy_rbf * 100:.2f}%\")\n",
        "\n",
        "#Comparison\n",
        "if accuracy_linear > accuracy_rbf:\n",
        "  print(\"Linear kernel performed better.\")\n",
        "elif accuracy_rbf > accuracy_linear:\n",
        "  print(\"RBF kernel performed better.\")\n",
        "else:\n",
        "  print(\"Both kernels performed equally well.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebZTs1OEmrps"
      },
      "source": [
        "## **Q23. Write a Python program to train an SVM Regressor (SVR) on a housing dataset and evaluate it using Mean Squared Error (MSE).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paVC7_v6oHWD"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X = housing.data\n",
        "y = housing.target\n",
        "\n",
        "#split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "#feature scaling\n",
        "scaler  =StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "#Train an SVR model with RBF kernel\n",
        "svr_model = SVR(kernel='rbf')\n",
        "svr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "#predict on the test set\n",
        "y_pred = svr_model.predict(X_test_scaled)\n",
        "\n",
        "#evaluate the model using MSE\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGbbiQ5kp9VH"
      },
      "source": [
        "## **Q24.Write a Python program to train an SVM Classifier with a Polynomial Kernel and visualize the decision boundary.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQBzMLvjqI__"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#Generate a synthetic 2d classification dataset\n",
        "X, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0,\n",
        "                           n_clusters_per_class=1, random_state=42)\n",
        "\n",
        "#standardize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "#train on SVM classifier with a polynomial kernel\n",
        "svm  = SVC(kernel='poly', degree=3, C=1.0)\n",
        "svm.fit(X,y)\n",
        "\n",
        "#create a mesh to plot decision boundaries\n",
        "x_min, x_max = X[:,0].min() - 1, X[:,0].max() +1\n",
        "y_min, y_max = X[:,1].min() - 1, X[:,1].max() +1\n",
        "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 500),\n",
        "                     np.linspace(y_min, y_max, 500)\n",
        "                     )\n",
        "Z = svm.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "#plot the decision boundary and data points\n",
        "plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.coolwarm)\n",
        "plt.scatter(X[:,0], X[:,1], c=y, cmap=plt.cm.coolwarm, edgecolors='k')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.title('SVM Decision Boundary')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QEsRKJJxUiN"
      },
      "source": [
        "## **Q25.Write a Python program to train a Gaussian Na√Øve Bayes classifier on the Breast Cancer dataset and evaluate accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dQndFWgxdHt"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#initialize and train the Gaussian Naive Bayes classifier\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "#make predictions\n",
        "y_pred = gnb.predict(X_test)\n",
        "\n",
        "#evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of Gaussian Naive Bayes classifier : {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXAIvLMYy5-q"
      },
      "source": [
        "## **Q26.Write a Python program to train a Multinomial Na√Øve Bayes classifier for text classification using the 20 Newsgroups dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMBx03wqEzqo"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "#load the 20 newsgroups (use subset for speed)\n",
        "categories = ['rec.sport.baseball', 'rec.autos', 'sci.med', 'comp.graphics']\n",
        "data = fetch_20newsgroups(subset='all', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "#split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=1)\n",
        "\n",
        "#create a pipeline with Countvectorizer and MultinomialNB\n",
        "model = make_pipeline(CountVectorizer(), MultinomialNB())\n",
        "\n",
        "#train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#predict on test data\n",
        "y_pred =  model.predict(X_test)\n",
        "\n",
        "#evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%\\n')\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, y_pred, target_names=data.target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5zu39Vwo92J"
      },
      "source": [
        "## **Q27.Write a Python program to train an SVM Classifier with different C values and compare the decision boundaries visually.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyCctPHNQr0O"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#Generate synthetic 2D dataset\n",
        "X, y = make_classification(\n",
        "    n_samples=100, n_features=2, n_informative=2, n_redundant=0,\n",
        "    n_clusters_per_class=1, random_state=42\n",
        ")\n",
        "\n",
        "#Standardize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "#Define different C values\n",
        "C_values = [0.01, 0.1, 1, 10, 100]\n",
        "\n",
        "#Set up the plot grid\n",
        "fig, axes = plt.subplots(1, len(C_values), figsize=(20, 4))\n",
        "\n",
        "#Create mesh for decision boundary plotting\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(\n",
        "    np.linspace(x_min, x_max, 300),\n",
        "    np.linspace(y_min, y_max, 300)\n",
        ")\n",
        "\n",
        "#Train and plot for each C value\n",
        "for ax, C in zip(axes, C_values):\n",
        "    svm = SVC(kernel='linear', C=C)\n",
        "    svm.fit(X, y)\n",
        "\n",
        "    Z = svm.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    ax.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.coolwarm)\n",
        "    ax.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.coolwarm)\n",
        "    ax.set_title(f\"SVM with C={C}\")\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle(\"Effect of Different C Values on SVM Decision Boundaries\", fontsize=16, y=1.05)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be-RI3Ccj9TJ"
      },
      "source": [
        "## **Q28.Write a Python program to train a Bernoulli Na√Øve Bayes classifier for binary classification on a dataset with binary features.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfUh0xeekGpb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import Binarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "#create a binary classification dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=0, n_classes=2, random_state=42\n",
        "                           )\n",
        "\n",
        "#Binarize the features (convert to 0/1)\n",
        "binarizer = Binarizer(threshold=0.0)\n",
        "X_binary = binarizer.fit_transform(X)\n",
        "\n",
        "#split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#train a Bernoulli Naive Bayes classifier\n",
        "bnb = BernoulliNB()\n",
        "bnb.fit(X_train, y_train)\n",
        "\n",
        "#make prediction\n",
        "y_pred = bnb.predict(X_test)\n",
        "\n",
        "#evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5zTDmRMoqDV"
      },
      "source": [
        "## **Q29.Write a Python program to apply feature scaling before training an SVM model and compare results with unscaled data.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dybkwo1LuiSs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "#create a binary classifiation dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=0, n_classes=2, random_state=42)\n",
        "\n",
        "#Binarize the features (convert to 0/1)\n",
        "binarizer = Binarizer(threshold=0.0)\n",
        "X_binary = binarizer.fit_transform(X)\n",
        "\n",
        "#split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#train a Bernoulli Naive Bayes classifier\n",
        "bnb = BernoulliNB()\n",
        "bnb.fit(X_train, y_train)\n",
        "\n",
        "#evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy:{accuracy * 100:.2f}%')\n",
        "print('\\nClassification Report:')\n",
        "print(classification_report (y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhgKVUT61OiH"
      },
      "source": [
        "## **Q30.Write a Python program to train a Gaussian Na√Øve Bayes model and compare the predictions before and after Laplace Smoothing.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fniAALWk1XAL"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#smaple toy text data\n",
        "texts = [\n",
        "    \"rainy weather cold\",\n",
        "    \"sunny weather hot,\",\n",
        "    \"rainy rainy cold\",\n",
        "    \"hot weather sunny\",\n",
        "    \"sunny sunny hot\",\n",
        "    \"cold cold rainy\"\n",
        "    ]\n",
        "\n",
        "labels=[0, 1, 0, 1, 1, 0] #0 = cold class, 1 = hot class\n",
        "\n",
        "#convert text to count vectors\n",
        "vectorizer  = CountVectorizer()\n",
        "X = vectorizer.fit_transform(texts)\n",
        "\n",
        "#split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "#without Laplace smoothing\n",
        "model_no_smooth = MultinomialNB(alpha=0.0)\n",
        "model_no_smooth.fit(X_train, y_train)\n",
        "pred_no_smooth = model_no_smooth.predict(X_test)\n",
        "\n",
        "#with laplace smoothing (alpha=1.0)\n",
        "model_laplace = MultinomialNB(alpha=1.0)\n",
        "model_laplace.fit(X_train, y_train)\n",
        "pred_laplace = model_laplace.predict(X_test)\n",
        "\n",
        "#compare predictions\n",
        "for i, text in enumerate(X_test.toarray()):\n",
        "  print(f'Sample {i+1}:')\n",
        "  print(f'features: {text}')\n",
        "  print(f'Prediction without smoothing: {pred_no_smooth[i]}')\n",
        "  print(f'Prdictions with Laplace smoothing: {pred_laplace[i]}')\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJ97-gysQd9D"
      },
      "source": [
        "## **Q31.Write a Python program to train an SVM Classifier and use GridSearchCV to tune the hyperparameters (C, gamma, kernel).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fo_mzvoQqDc"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#load the dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "#split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "#define the parameter grid\n",
        "param_grid = {\n",
        "    'C':[0.1, 1, 10, 100],\n",
        "    'gamma': ['scale', 'auto', 0.01, 0.1],\n",
        "    'kernel': ['linear', 'rbf', 'poly']\n",
        "}\n",
        "\n",
        "\n",
        "#initialize the SVM Model\n",
        "svc = SVC()\n",
        "\n",
        "#apply GridSearchCV\n",
        "grid_search = GridSearchCV(svc, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "#print best parameters and score\n",
        "print('Best Parameters:')\n",
        "print(grid_search.best_params_)\n",
        "print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.2f}\")\n",
        "\n",
        "#evaluate on test data\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "print('\\nClassification Report on Test Data:')\n",
        "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foW93rhUVfYU"
      },
      "source": [
        "## **Q32.Write a Python program to train an SVM Classifier on an imbalanced dataset and apply class weighting and check it improve accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwChVvfqVlQg"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#Generate an imbalanced dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=2, n_informative=2,\n",
        "                           n_redundant=0, n_clusters_per_class=1,\n",
        "                           weights=[0.9, 0.1], flip_y=0, random_state=42)\n",
        "\n",
        "#Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "#Train SVM without class weighting\n",
        "svm_plain = SVC(kernel='rbf', C=1.0)\n",
        "svm_plain.fit(X_train, y_train)\n",
        "y_pred_plain = svm_plain.predict(X_test)\n",
        "\n",
        "#Train SVM with class weighting\n",
        "svm_weighted = SVC(kernel='rbf', C=1.0, class_weight='balanced')\n",
        "svm_weighted.fit(X_train, y_train)\n",
        "y_pred_weighted = svm_weighted.predict(X_test)\n",
        "\n",
        "#Evaluation\n",
        "print(\"Without Class Weighting\")\n",
        "print(classification_report(y_test, y_pred_plain))\n",
        "print(\"Confusion Matrix:\")\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_plain), annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"Without Class Weighting\")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n With Class Weighting\")\n",
        "print(classification_report(y_test, y_pred_weighted))\n",
        "print(\"Confusion Matrix:\")\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_weighted), annot=True, fmt='d', cmap='Greens')\n",
        "plt.title(\"With Class Weighting\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nj-3nIcMXC6P"
      },
      "source": [
        "## **Q33.Write a Python program to implement a Na√Øve Bayes classifier for spam detection using email data.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sz0WHPtJXKQJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#load dataset\n",
        "url = \"https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv\"\n",
        "data = pd.read_csv(url, sep='\\t', header=None,  names=['label', 'message'])\n",
        "\n",
        "#convert labels to binary\n",
        "data['label'] = data['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "#split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['message'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "#vectorize the text data\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "#train a Naive Bayes classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train_vec, y_train)\n",
        "\n",
        "#predict and evaluate\n",
        "y_pred = nb_classifier.predict(X_test_vec)\n",
        "\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Ham', 'spam']))\n",
        "\n",
        "print(\"\\n Confusion Matrix\")\n",
        "conf_mat = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=['Ham','Spam'], yticklabels=['Ham', 'Spam'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title(\"Spam Detection Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n Accuracy: {accuracy_score(y_test, y_pred):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyuXgwOKmxfs"
      },
      "source": [
        "## **Q34.Write a Python program to train an SVM Classifier and a Na√Øve Bayes Classifier on the same dataset and compare their accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_Nai3fOm5UY"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "#load the dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "#train an SVM classifier\n",
        "\n",
        "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
        "svm_model.fit(X_train, y_train)\n",
        "svm_preds = svm_model.predict(X_test)\n",
        "\n",
        "\n",
        "#Train a Na√Øve Bayes classifier\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "nb_preds = nb_model.predict(X_test)\n",
        "\n",
        "#evaluate and compare\n",
        "svm_acc = accuracy_score(y_test, svm_preds)\n",
        "nb_acc = accuracy_score(y_test, nb_preds)\n",
        "\n",
        "print(\"SVM Classifier Report\")\n",
        "print(classification_report(y_test, svm_preds, target_names=iris.target_names))\n",
        "print(f\"SVM Accuracy: {svm_acc:.2f}\")\n",
        "\n",
        "print(\"\\nNa√Øve Bayes Classifier Report\")\n",
        "print(classification_report(y_test, nb_preds, target_names=iris.target_names))\n",
        "print(f\"Na√Øve Bayes Accuracy: {nb_acc:.2f}\")\n",
        "\n",
        "# Step 6: Comparison Summary\n",
        "print(\"\\nComparison Summary\")\n",
        "if svm_acc > nb_acc:\n",
        "    print(\"SVM performed better.\")\n",
        "elif nb_acc > svm_acc:\n",
        "    print(\"Na√Øve Bayes performed better.\")\n",
        "else:\n",
        "    print(\"Both classifiers performed equally well.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4jWX11gqelv"
      },
      "source": [
        "## **Q35.Write a Python program to perform feature selection before training a Na√Øve Bayes classifier and compare results.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymcGkxUhq0fB"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "#Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "#Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "#Train Na√Øve Bayes without feature selection\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred_full = nb.predict(X_test)\n",
        "acc_full = accuracy_score(y_test, y_pred_full)\n",
        "\n",
        "#Perform feature selection (SelectKBest)\n",
        "selector = SelectKBest(score_func=f_classif, k=10)\n",
        "X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "X_test_selected = selector.transform(X_test)\n",
        "\n",
        "#Train Na√Øve Bayes with selected features\n",
        "nb_selected = GaussianNB()\n",
        "nb_selected.fit(X_train_selected, y_train)\n",
        "y_pred_selected = nb_selected.predict(X_test_selected)\n",
        "acc_selected = accuracy_score(y_test, y_pred_selected)\n",
        "\n",
        "#Print results\n",
        "print(\">>>>>Without Feature Selection<<<<<<\")\n",
        "print(classification_report(y_test, y_pred_full, target_names=data.target_names))\n",
        "print(f\"Accuracy: {acc_full:.2f}\")\n",
        "\n",
        "print(\"\\n>>>>>With Feature Selection (Top 10 features)<<<<<\")\n",
        "print(classification_report(y_test, y_pred_selected, target_names=data.target_names))\n",
        "print(f\"Accuracy: {acc_selected:.2f}\")\n",
        "\n",
        "#Summary\n",
        "print(\"\\n>>>>>>>Summary<<<<<<<\")\n",
        "if acc_selected > acc_full:\n",
        "    print(\"Feature selection improved accuracy.\")\n",
        "elif acc_selected < acc_full:\n",
        "    print(\"Feature selection reduced accuracy.\")\n",
        "else:\n",
        "    print(\"Accuracy remained the same after feature selection.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkp-3HuxsJ_T"
      },
      "source": [
        "## **Q36.Write a Python program to train an SVM Classifier using One-vs-Rest (OvR) and One-vs-One (OvO) strategies on the Wine dataset and compare their accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dL4Gj0UqsR6M"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "#load the dataset\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "#split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "#train SVM using One-vs-Rest strategy\n",
        "ovr_model = OneVsRestClassifier(SVC(kernel='rbf', gamma='scale'))\n",
        "ovr_model.fit(X_train, y_train)\n",
        "ovr_preds = ovr_model.predict(X_test)\n",
        "ovr_acc = accuracy_score(y_test, ovr_preds)\n",
        "\n",
        "#train SVM using One-vs-One strategy\n",
        "ovo_model = OneVsOneClassifier(SVC(kernel='rbf', gamma='scale'))\n",
        "ovo_model.fit(X_train, y_train)\n",
        "ovo_preds = ovo_model.predict(X_test)\n",
        "ovo_acc = accuracy_score(y_test, ovo_preds)\n",
        "\n",
        "#print results\n",
        "print(\">>>One-vs-Rest (OvR) Classification Report<<<\")\n",
        "print(classification_report(y_test, ovr_preds, target_names=wine.target_names))\n",
        "print(f\"Accuracy(OvR): {ovr_acc:.2f}\")\n",
        "\n",
        "print(\"\\n>>>One-vs-One (OvO) Classification Report<<<\")\n",
        "print(classification_report(y_test, ovo_preds, target_names=wine.target_names))\n",
        "print(f\"Accuracy(OvO): {ovo_acc:.2f}\")\n",
        "\n",
        "#Comparison\n",
        "print(\"\\n>>>Comparison Summery<<<\")\n",
        "if ovr_acc  > ovo_acc:\n",
        "     print(\"Ove-vs-Rest (OvR) performed better.\")\n",
        "elif ovo_acc > ovr_acc:\n",
        "     print(\"One-vs-One (OvO) performed better.\")\n",
        "else:\n",
        "     print(\"Both OvR and OvO archieved the same accuracy.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qVkRNjsxJUn"
      },
      "source": [
        "## **Q37.Write a Python program to train an SVM Classifier using Linear, Polynomial, and RBF kernels on the Breast Cancer dataset and compare their accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AA8e99rLxS4r"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "#load the dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "#Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "#train SVM with linear kernel\n",
        "svm_linear = SVC(kernel='linear')\n",
        "svm_linear.fit(X_train, y_train)\n",
        "y_pred_linear = svm_linear.predict(X_test)\n",
        "acc_linear = accuracy_score(y_test, y_pred_linear)\n",
        "\n",
        "#train SVM with polynomial kernel\n",
        "svm_poly = SVC(kernel='poly', degree=3)\n",
        "svm_poly.fit(X_train, y_train)\n",
        "y_pred_poly = svm_poly.predict(X_test)\n",
        "acc_poly = accuracy_score(y_test, y_pred_poly)\n",
        "\n",
        "#train SVM with RBF kernel\n",
        "svm_rbf = SVC(kernel='rbf')\n",
        "svm_rbf.fit(X_train, y_train)\n",
        "y_pred_rbf = svm_rbf.predict(X_test)\n",
        "acc_rbf = accuracy_score(y_test, y_pred_rbf)\n",
        "\n",
        "\n",
        "#Display results\n",
        "print(\"=== SVM with Linear Kernel ===\")\n",
        "print(f\"Accuracy: {acc_linear:.2f}\")\n",
        "print(classification_report(y_test, y_pred_linear, target_names=data.target_names))\n",
        "\n",
        "print(\"\\n=== SVM with Polynomial Kernel ===\")\n",
        "print(f\"Accuracy: {acc_poly:.2f}\")\n",
        "print(classification_report(y_test, y_pred_poly, target_names=data.target_names))\n",
        "\n",
        "print(\"\\n=== SVM with RBF Kernel ===\")\n",
        "print(f\"Accuracy: {acc_rbf:.2f}\")\n",
        "print(classification_report(y_test, y_pred_rbf, target_names=data.target_names))\n",
        "\n",
        "# Step 7: Summary\n",
        "print(\"\\n=== Accuracy Comparison ===\")\n",
        "print(f\"Linear Kernel Accuracy:     {acc_linear:.2f}\")\n",
        "print(f\"Polynomial Kernel Accuracy: {acc_poly:.2f}\")\n",
        "print(f\"RBF Kernel Accuracy:        {acc_rbf:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_5Jbbo959Pw"
      },
      "source": [
        "## **Q38.Write a Python program to train an SVM Classifier using Stratified K-Fold Cross-Validation and compute the average accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vM48QGtK6DYq"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "#Initialize StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "#Initialize SVM\n",
        "model = SVC(kernel='rbf', gamma='scale')\n",
        "\n",
        "#Cross-validation\n",
        "accuracies = []\n",
        "\n",
        "for fold, (train_index, text_index) in enumerate(skf.split(X,y), 1):\n",
        "  X_train, X_test = X[train_index], X[text_index]\n",
        "  y_train, y_test = y[train_index], y[text_index]\n",
        "\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  acc = accuracy_score(y_test, y_pred)\n",
        "  accuracies.append(acc)\n",
        "  print(f\"Fold {fold}: Accuracy = {acc:.2f}\")\n",
        "\n",
        "#average accuracy\n",
        "mean_acc = np.mean(accuracies)\n",
        "print(f\"\\nAverage Accuracy over{skf.get_n_splits()} folds: {mean_acc:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tw7RLxBh9jyZ"
      },
      "source": [
        "## **Q39.Write a Python program to train a Na√Øve Bayes classifier using different prior probabilities and compare performance.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCOWxW5-aP0g"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "#Load the Iris dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "target_names = data.target_names\n",
        "\n",
        "#Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "#Define different prior probabilities\n",
        "priors_list = [\n",
        "    None,   #Default priors\n",
        "    [1/3, 1/3, 1/3],#Uniform priors\n",
        "    [0.7, 0.2, 0.1],#Skewed towards class 0\n",
        "    [0.1, 0.7, 0.2],#Skewed towards class 1\n",
        "]\n",
        "\n",
        "#train and evaluate with each set of priors\n",
        "for i, priors in enumerate(priors_list, start=1):\n",
        "    model = GaussianNB(priors=priors)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\n>>>Model {i}: Priors = {priors}<<<<\")\n",
        "    print(f\"Accuracy: {acc:.2f}\")\n",
        "    print(classification_report(y_test, y_pred, target_names=target_names))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCwgeZB4blbw"
      },
      "source": [
        "## **Q40.Write a Python program to perform Recursive Feature Elimination (RFE) before training an SVM Classifier and compare accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lROaHyxAcPJv"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "#tarin split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "#train SVM without feature selection\n",
        "model_full = SVC(kernel='linear')\n",
        "model_full.fit(X_train, y_train)\n",
        "y_pred_full = model_full.predict(X_test)\n",
        "acc_full = accuracy_score(y_test, y_pred_full)\n",
        "print(f'Accuracy without RFE: {acc_full:.2f}')\n",
        "\n",
        "#apply recursive feature elimination (RFE)\n",
        "rfe = RFE(estimator=SVC(kernel='linear'), n_features_to_select=10)\n",
        "rfe.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "#transform features\n",
        "X_train_rfe = rfe.transform(X_train)\n",
        "X_test_rfe = rfe.transform(X_test)\n",
        "\n",
        "#train SVM with selected features\n",
        "model_rfe = SVC(kernel='linear')\n",
        "model_rfe.fit(X_train_rfe, y_train)\n",
        "y_pred_rfe = model_rfe.predict(X_test_rfe)\n",
        "acc_rfe = accuracy_score(y_test, y_pred_rfe)\n",
        "print(f'Accuracy with RFE(top 10 features): {acc_rfe:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc8wHsupgQ5R"
      },
      "source": [
        "## **Q41.Write a Python program to train an SVM Classifier and evaluate its performance using Precision, Recall, and F1-Score instead of accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvszA80Qgd3h"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "#load the data\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "#split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "#intialize and train the SVM classifier\n",
        "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "#ppredict the test data\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "#evaluate using precision , recall and F1-score\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n",
        "\n",
        "#get macro/micro avearage scores individually\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "\n",
        "print(f'Macro Precision: {precision:.2f}')\n",
        "print(f'Macri Recall: {recall:.2f}')\n",
        "print(f'Macro F1-Score: {f1:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-zdhnC5Ipht"
      },
      "source": [
        "## **Q42.Write a Python program to train a Na√Øve Bayes Classifier and evaluate its performance using Log Loss (Cross-Entropy Loss).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJYLvLR4I4Xz"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "#load the dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "#split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "#initialize and train the Gaussian Naive Bayes model\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "#Predict class probabilities on the test set\n",
        "y_prob = nb_model.predict_proba(X_test)\n",
        "\n",
        "#compute Log Loss (Cross-Entropy Loss)\n",
        "loss = log_loss(y_test, y_prob)\n",
        "\n",
        "print(f\"Log Loss (Cross-Entropy Loss): {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq5y6RPzNZww"
      },
      "source": [
        "## **Q43.Write a Python program to train an SVM Classifier and visualize the Confusion Matrix using seaborn**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s38Ar0dUNfi7"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "#load dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "class_names = iris.target_names\n",
        "\n",
        "#split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "      X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "#train an SVM classifier\n",
        "svm_model = SVC(kernel='rbf', C=1.0)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "#make preditions\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "#compute the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "#visualize the confusion matrix\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix - SVM Classifier')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-_LWYBEPzbd"
      },
      "source": [
        "## **Q44.Write a Python program to train an SVM Regressor (SVR) and evaluate its performance using Mean Absolute Error (MAE) instead of MSE.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4T0ssyNQa_Ze",
        "outputId": "d2753840-45f8-45c0-c849-e96b64902659"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 0.3832\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "#Load dataset\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "#Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#Train SVR\n",
        "svr_model = SVR(kernel='rbf', C=10, gamma=0.1)  # Adjusted for speed\n",
        "svr_model.fit(X_train, y_train)\n",
        "\n",
        "#Predict\n",
        "y_pred = svr_model.predict(X_test)\n",
        "\n",
        "#Evaluate using MAE\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"Mean Absolute Error: {mae:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqKlPbn5cVPx"
      },
      "source": [
        "## **Q45.Write a Python program to train a Na√Øve Bayes classifier and evaluate its performance using the ROC-AUC score.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KSb_WeyGcccJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "7ad422de-27e4-4498-eb4a-dc7331859f57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9901\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Load the dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "#Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "#Train a Na√Øve Bayes classifier\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "#Predict probabilities\n",
        "y_proba = nb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "#Calculate ROC-AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_proba)\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "\n",
        "#Plot the ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve - Na√Øve Bayes')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q46.Write a Python program to train an SVM Classifier and visualize the Precision-Recall Curve.**"
      ],
      "metadata": {
        "id": "XqlTZWqNvn0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "\n",
        "#Load dataset (binary classification)\n",
        "data = datasets.load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "#Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "#Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#Train SVM with probability estimates\n",
        "svm_clf = SVC(kernel='rbf', C=1.0, probability=True, random_state=42)\n",
        "svm_clf.fit(X_train, y_train)\n",
        "\n",
        "#Get predicted probabilities for class 1\n",
        "y_scores = svm_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "#Calculate precision-recall values\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
        "avg_precision = average_precision_score(y_test, y_scores)\n",
        "\n",
        "#Plot Precision-Recall curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, color='blue', linewidth=2, label=f'Avg Precision = {avg_precision:.2f}')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve for SVM Classifier')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "vzZTISvMvtAU",
        "outputId": "8d3f64b6-4fda-464a-a266-335113aa1dd5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "QIFCCrpnp8GC",
        "T6xS2GijbHmf",
        "HNIZx-TebHpo",
        "jk0cd17Qb6X7",
        "gN6ZQr979sgq",
        "aHgxRcejBQxc",
        "ofxyIwKdEFq1",
        "Fmnmczg0I4jq",
        "HOnkLs1SKgI_",
        "p1U3UGu8NMAS",
        "XNgjknwGOgaI",
        "PRCmfTUKPRCs",
        "sJijhHBFQqeB",
        "0jL3Mn9cUBFb",
        "F5FK8W7vWDOz",
        "OSiuhDJ5YqdG",
        "zCLdqfhAZW2O",
        "3ND8AdZ6ZjdZ",
        "pT5o74TicNWV",
        "k4a6pBUhequ8",
        "e0pzSQMWkbVH",
        "YAYPY-jeqEss",
        "SOlEYITZqKfF",
        "emlA_M-yhZZV",
        "ebZTs1OEmrps",
        "tGbbiQ5kp9VH",
        "9QEsRKJJxUiN",
        "cXAIvLMYy5-q",
        "A5zu39Vwo92J",
        "be-RI3Ccj9TJ",
        "E5zTDmRMoqDV",
        "EhgKVUT61OiH",
        "GJ97-gysQd9D",
        "foW93rhUVfYU",
        "nj-3nIcMXC6P",
        "wyuXgwOKmxfs",
        "B4jWX11gqelv",
        "lkp-3HuxsJ_T",
        "1qVkRNjsxJUn",
        "V_5Jbbo959Pw",
        "tw7RLxBh9jyZ",
        "WCwgeZB4blbw",
        "Dc8wHsupgQ5R",
        "7-zdhnC5Ipht",
        "Hq5y6RPzNZww",
        "E-_LWYBEPzbd",
        "hqKlPbn5cVPx",
        "XqlTZWqNvn0f"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}